{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = Path(\"../processed data/hotel_bookings_final.pkl\")\n",
        "df = pd.read_pickle(data_path)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[\"is_canceled\"])\n",
        "y = df[\"is_canceled\"]\n",
        "\n",
        "# Scale features for PCA stability\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2, random_state=42)\n",
        "pca_components = pca.fit_transform(X_scaled)\n",
        "\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "print(\"Explained variance ratios:\", explained_var)\n",
        "print(\"Cumulative variance (2 components):\", explained_var.sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=pca_components[:,0], y=pca_components[:,1], hue=y, palette=\"coolwarm\", alpha=0.6)\n",
        "plt.title(\"PCA: Bookings Colored by Cancellation\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend(title=\"is_canceled\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA loadings to see which features drive each component\n",
        "loadings = pd.DataFrame(pca.components_, columns=X.columns, index=[\"PC1\",\"PC2\"])\n",
        "\n",
        "# Top absolute loadings per component\n",
        "for pc in loadings.index:\n",
        "    top_features = loadings.loc[pc].abs().sort_values(ascending=False).head(10)\n",
        "    print(f\"\\nTop contributors for {pc}:\")\n",
        "    print(top_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save PCA components for downstream visualization\n",
        "output_dir = Path(\"../processed data\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\",\"PC2\"])\n",
        "pca_df[\"is_canceled\"] = y.reset_index(drop=True)\n",
        "\n",
        "pca_df.to_pickle(output_dir / \"hotel_pca_components.pkl\")\n",
        "loadings.to_pickle(output_dir / \"hotel_pca_loadings.pkl\")\n",
        "\n",
        "pca_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Cluster on the 2D PCA space\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(pca_components)\n",
        "\n",
        "pca_df[\"cluster\"] = clusters\n",
        "pca_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=pca_df[\"PC1\"],\n",
        "    y=pca_df[\"PC2\"],\n",
        "    hue=pca_df[\"cluster\"].astype(str),\n",
        "    palette=\"tab10\",\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title(\"PCA Clusters (KMeans on PC1 & PC2)\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarize top positive/negative loadings for each component\n",
        "n_top = 6\n",
        "for pc in [\"PC1\", \"PC2\"]:\n",
        "    comp = loadings.loc[pc]\n",
        "    top_pos = comp.sort_values(ascending=False).head(n_top)\n",
        "    top_neg = comp.sort_values().head(n_top)\n",
        "    print(f\"\\n{pc} — top +loadings:\")\n",
        "    print(top_pos)\n",
        "    print(f\"\\n{pc} — top -loadings:\")\n",
        "    print(top_neg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to read these components\n",
        "- **PC1**: Driven by the largest positive/negative loadings above. High positive scores come from the +loading features; high negative scores from the -loading features. Interpret by checking which operational/booking behaviors these features represent.\n",
        "- **PC2**: Same idea—use the loadings table and the top +/- summaries to label this axis (e.g., “long lead / higher ADR” vs “short lead / lower ADR” if those appear in your outputs).\n",
        "- **Clusters**: Points are grouped in PCA space; inspect each cluster’s centroid (via the KMeans labels) to see which PC directions they lean toward. You can also merge `pca_df` back to the original data on index to profile clusters by room type, deposit type, or lead time.\n",
        "- **Next step (optional)**: Add a small profiling cell to compute per-cluster means of the original key features (lead_time, adr, deposit_type indicators, etc.) to narrate “Cluster 0 looks like X, Cluster 1 like Y.”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick cluster profile on a few interpretable (scaled) features\n",
        "key_cols = [\n",
        "    \"lead_time\",\n",
        "    \"adr\",\n",
        "    \"total_of_special_requests\",\n",
        "    \"previous_cancellations\",\n",
        "    \"booking_changes\",\n",
        "    \"deposit_type_Non Refund\",\n",
        "    \"deposit_type_Refundable\",\n",
        "    \"market_segment_Online TA\",\n",
        "    \"market_segment_Groups\",\n",
        "    \"distribution_channel_Online TA\",\n",
        "]\n",
        "\n",
        "present_cols = [c for c in key_cols if c in df.columns]\n",
        "cluster_profile = (\n",
        "    pd.concat([df.reset_index(drop=True), pca_df[[\"cluster\"]]], axis=1)\n",
        "      .groupby(\"cluster\")[present_cols]\n",
        "      .mean()\n",
        ")\n",
        "\n",
        "print(\"Cluster profile (scaled feature means):\")\n",
        "cluster_profile\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
